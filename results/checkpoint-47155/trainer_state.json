{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 47155,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05301664722722935,
      "grad_norm": 21.685094833374023,
      "learning_rate": 1.9789629943802355e-05,
      "loss": 0.1221,
      "step": 500
    },
    {
      "epoch": 0.1060332944544587,
      "grad_norm": 0.18682068586349487,
      "learning_rate": 1.9577987488071256e-05,
      "loss": 0.1402,
      "step": 1000
    },
    {
      "epoch": 0.15904994168168804,
      "grad_norm": 1.3096438646316528,
      "learning_rate": 1.9365920899162338e-05,
      "loss": 0.1597,
      "step": 1500
    },
    {
      "epoch": 0.2120665889089174,
      "grad_norm": 11.586978912353516,
      "learning_rate": 1.915385431025342e-05,
      "loss": 0.1435,
      "step": 2000
    },
    {
      "epoch": 0.26508323613614676,
      "grad_norm": 0.40514203906059265,
      "learning_rate": 1.8941787721344503e-05,
      "loss": 0.1396,
      "step": 2500
    },
    {
      "epoch": 0.3180998833633761,
      "grad_norm": 1.3419859409332275,
      "learning_rate": 1.8729721132435585e-05,
      "loss": 0.1394,
      "step": 3000
    },
    {
      "epoch": 0.37111653059060545,
      "grad_norm": 0.6653173565864563,
      "learning_rate": 1.8517654543526668e-05,
      "loss": 0.1621,
      "step": 3500
    },
    {
      "epoch": 0.4241331778178348,
      "grad_norm": 11.843262672424316,
      "learning_rate": 1.8306012087795568e-05,
      "loss": 0.153,
      "step": 4000
    },
    {
      "epoch": 0.47714982504506415,
      "grad_norm": 0.1835305392742157,
      "learning_rate": 1.809394549888665e-05,
      "loss": 0.1502,
      "step": 4500
    },
    {
      "epoch": 0.5301664722722935,
      "grad_norm": 0.5986570715904236,
      "learning_rate": 1.7881878909977733e-05,
      "loss": 0.1557,
      "step": 5000
    },
    {
      "epoch": 0.5831831194995228,
      "grad_norm": 20.185476303100586,
      "learning_rate": 1.766981232106882e-05,
      "loss": 0.154,
      "step": 5500
    },
    {
      "epoch": 0.6361997667267522,
      "grad_norm": 0.18737705051898956,
      "learning_rate": 1.7457745732159898e-05,
      "loss": 0.1449,
      "step": 6000
    },
    {
      "epoch": 0.6892164139539816,
      "grad_norm": 1.1421095132827759,
      "learning_rate": 1.724567914325098e-05,
      "loss": 0.1581,
      "step": 6500
    },
    {
      "epoch": 0.7422330611812109,
      "grad_norm": 0.15071715414524078,
      "learning_rate": 1.7034036687519884e-05,
      "loss": 0.1507,
      "step": 7000
    },
    {
      "epoch": 0.7952497084084402,
      "grad_norm": 0.21897344291210175,
      "learning_rate": 1.6821970098610963e-05,
      "loss": 0.1513,
      "step": 7500
    },
    {
      "epoch": 0.8482663556356697,
      "grad_norm": 22.7653751373291,
      "learning_rate": 1.660990350970205e-05,
      "loss": 0.159,
      "step": 8000
    },
    {
      "epoch": 0.901283002862899,
      "grad_norm": 0.6564773321151733,
      "learning_rate": 1.639783692079313e-05,
      "loss": 0.1662,
      "step": 8500
    },
    {
      "epoch": 0.9542996500901283,
      "grad_norm": 2.1388449668884277,
      "learning_rate": 1.618577033188421e-05,
      "loss": 0.1691,
      "step": 9000
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.42403265833854675,
      "eval_runtime": 121.5625,
      "eval_samples_per_second": 411.286,
      "eval_steps_per_second": 25.707,
      "step": 9431
    },
    {
      "epoch": 1.0073162973173577,
      "grad_norm": 0.40549325942993164,
      "learning_rate": 1.5974127876153114e-05,
      "loss": 0.1574,
      "step": 9500
    },
    {
      "epoch": 1.060332944544587,
      "grad_norm": 11.330903053283691,
      "learning_rate": 1.5762061287244196e-05,
      "loss": 0.106,
      "step": 10000
    },
    {
      "epoch": 1.1133495917718164,
      "grad_norm": 9.68647575378418,
      "learning_rate": 1.554999469833528e-05,
      "loss": 0.1122,
      "step": 10500
    },
    {
      "epoch": 1.1663662389990457,
      "grad_norm": 2.389604330062866,
      "learning_rate": 1.533792810942636e-05,
      "loss": 0.1172,
      "step": 11000
    },
    {
      "epoch": 1.219382886226275,
      "grad_norm": 0.17942017316818237,
      "learning_rate": 1.5125861520517444e-05,
      "loss": 0.1243,
      "step": 11500
    },
    {
      "epoch": 1.2723995334535045,
      "grad_norm": 9.308012962341309,
      "learning_rate": 1.4914219064786344e-05,
      "loss": 0.1025,
      "step": 12000
    },
    {
      "epoch": 1.3254161806807336,
      "grad_norm": 166.41046142578125,
      "learning_rate": 1.4702576609055244e-05,
      "loss": 0.114,
      "step": 12500
    },
    {
      "epoch": 1.3784328279079632,
      "grad_norm": 6.816244602203369,
      "learning_rate": 1.4490510020146327e-05,
      "loss": 0.1109,
      "step": 13000
    },
    {
      "epoch": 1.4314494751351925,
      "grad_norm": 0.3866661489009857,
      "learning_rate": 1.4278443431237409e-05,
      "loss": 0.1237,
      "step": 13500
    },
    {
      "epoch": 1.4844661223624218,
      "grad_norm": 0.7351087331771851,
      "learning_rate": 1.4066376842328493e-05,
      "loss": 0.1156,
      "step": 14000
    },
    {
      "epoch": 1.5374827695896511,
      "grad_norm": 0.09362664818763733,
      "learning_rate": 1.3854310253419574e-05,
      "loss": 0.1056,
      "step": 14500
    },
    {
      "epoch": 1.5904994168168805,
      "grad_norm": 0.167154461145401,
      "learning_rate": 1.3642243664510656e-05,
      "loss": 0.1202,
      "step": 15000
    },
    {
      "epoch": 1.64351606404411,
      "grad_norm": 5.570528984069824,
      "learning_rate": 1.343017707560174e-05,
      "loss": 0.1208,
      "step": 15500
    },
    {
      "epoch": 1.696532711271339,
      "grad_norm": 1.3276227712631226,
      "learning_rate": 1.3218110486692823e-05,
      "loss": 0.1116,
      "step": 16000
    },
    {
      "epoch": 1.7495493584985686,
      "grad_norm": 3.087017059326172,
      "learning_rate": 1.3006043897783904e-05,
      "loss": 0.1123,
      "step": 16500
    },
    {
      "epoch": 1.802566005725798,
      "grad_norm": 0.14564545452594757,
      "learning_rate": 1.2793977308874988e-05,
      "loss": 0.1201,
      "step": 17000
    },
    {
      "epoch": 1.8555826529530273,
      "grad_norm": 2.9178361892700195,
      "learning_rate": 1.2582334853143888e-05,
      "loss": 0.1099,
      "step": 17500
    },
    {
      "epoch": 1.9085993001802566,
      "grad_norm": 0.41565877199172974,
      "learning_rate": 1.237026826423497e-05,
      "loss": 0.1123,
      "step": 18000
    },
    {
      "epoch": 1.961615947407486,
      "grad_norm": 0.060686055570840836,
      "learning_rate": 1.2158201675326053e-05,
      "loss": 0.1166,
      "step": 18500
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.4743202030658722,
      "eval_runtime": 103.3279,
      "eval_samples_per_second": 483.867,
      "eval_steps_per_second": 30.244,
      "step": 18862
    },
    {
      "epoch": 2.0146325946347154,
      "grad_norm": 0.10067254304885864,
      "learning_rate": 1.1946135086417137e-05,
      "loss": 0.1057,
      "step": 19000
    },
    {
      "epoch": 2.0676492418619445,
      "grad_norm": 0.049108561128377914,
      "learning_rate": 1.1734492630686035e-05,
      "loss": 0.0706,
      "step": 19500
    },
    {
      "epoch": 2.120665889089174,
      "grad_norm": 1.2714452743530273,
      "learning_rate": 1.152242604177712e-05,
      "loss": 0.0702,
      "step": 20000
    },
    {
      "epoch": 2.173682536316403,
      "grad_norm": 17.944664001464844,
      "learning_rate": 1.1310359452868202e-05,
      "loss": 0.0756,
      "step": 20500
    },
    {
      "epoch": 2.2266991835436327,
      "grad_norm": 15.599995613098145,
      "learning_rate": 1.1098292863959283e-05,
      "loss": 0.0728,
      "step": 21000
    },
    {
      "epoch": 2.2797158307708623,
      "grad_norm": 2.6767003536224365,
      "learning_rate": 1.0886226275050367e-05,
      "loss": 0.0909,
      "step": 21500
    },
    {
      "epoch": 2.3327324779980914,
      "grad_norm": 0.7695866823196411,
      "learning_rate": 1.0674583819319267e-05,
      "loss": 0.0783,
      "step": 22000
    },
    {
      "epoch": 2.385749125225321,
      "grad_norm": 0.3333660662174225,
      "learning_rate": 1.046251723041035e-05,
      "loss": 0.0852,
      "step": 22500
    },
    {
      "epoch": 2.43876577245255,
      "grad_norm": 0.0683039203286171,
      "learning_rate": 1.0250450641501432e-05,
      "loss": 0.0789,
      "step": 23000
    },
    {
      "epoch": 2.4917824196797795,
      "grad_norm": 0.040583185851573944,
      "learning_rate": 1.0038808185770332e-05,
      "loss": 0.0744,
      "step": 23500
    },
    {
      "epoch": 2.544799066907009,
      "grad_norm": 66.37677001953125,
      "learning_rate": 9.826741596861415e-06,
      "loss": 0.0767,
      "step": 24000
    },
    {
      "epoch": 2.597815714134238,
      "grad_norm": 0.09506040066480637,
      "learning_rate": 9.614675007952497e-06,
      "loss": 0.0797,
      "step": 24500
    },
    {
      "epoch": 2.6508323613614673,
      "grad_norm": 0.3830834925174713,
      "learning_rate": 9.402608419043581e-06,
      "loss": 0.079,
      "step": 25000
    },
    {
      "epoch": 2.703849008588697,
      "grad_norm": 6.1212968826293945,
      "learning_rate": 9.190541830134662e-06,
      "loss": 0.0813,
      "step": 25500
    },
    {
      "epoch": 2.7568656558159264,
      "grad_norm": 1.9248981475830078,
      "learning_rate": 8.978899374403564e-06,
      "loss": 0.0829,
      "step": 26000
    },
    {
      "epoch": 2.8098823030431554,
      "grad_norm": 0.06936079263687134,
      "learning_rate": 8.766832785494646e-06,
      "loss": 0.0837,
      "step": 26500
    },
    {
      "epoch": 2.862898950270385,
      "grad_norm": 0.0490129180252552,
      "learning_rate": 8.554766196585729e-06,
      "loss": 0.0827,
      "step": 27000
    },
    {
      "epoch": 2.915915597497614,
      "grad_norm": 20.653396606445312,
      "learning_rate": 8.342699607676811e-06,
      "loss": 0.0809,
      "step": 27500
    },
    {
      "epoch": 2.9689322447248436,
      "grad_norm": 0.21931563317775726,
      "learning_rate": 8.130633018767894e-06,
      "loss": 0.0849,
      "step": 28000
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5520357489585876,
      "eval_runtime": 127.8536,
      "eval_samples_per_second": 391.049,
      "eval_steps_per_second": 24.442,
      "step": 28293
    },
    {
      "epoch": 3.021948891952073,
      "grad_norm": 35.770626068115234,
      "learning_rate": 7.918566429858976e-06,
      "loss": 0.0726,
      "step": 28500
    },
    {
      "epoch": 3.0749655391793023,
      "grad_norm": 2.3405518531799316,
      "learning_rate": 7.706923974127876e-06,
      "loss": 0.0556,
      "step": 29000
    },
    {
      "epoch": 3.127982186406532,
      "grad_norm": 0.04477695748209953,
      "learning_rate": 7.49485738521896e-06,
      "loss": 0.0525,
      "step": 29500
    },
    {
      "epoch": 3.180998833633761,
      "grad_norm": 0.027400393038988113,
      "learning_rate": 7.282790796310042e-06,
      "loss": 0.0586,
      "step": 30000
    },
    {
      "epoch": 3.2340154808609904,
      "grad_norm": 0.05710184574127197,
      "learning_rate": 7.070724207401125e-06,
      "loss": 0.0525,
      "step": 30500
    },
    {
      "epoch": 3.2870321280882195,
      "grad_norm": 14.565143585205078,
      "learning_rate": 6.858657618492207e-06,
      "loss": 0.0528,
      "step": 31000
    },
    {
      "epoch": 3.340048775315449,
      "grad_norm": 0.023983921855688095,
      "learning_rate": 6.646591029583289e-06,
      "loss": 0.0541,
      "step": 31500
    },
    {
      "epoch": 3.393065422542678,
      "grad_norm": 0.06869884580373764,
      "learning_rate": 6.43494857385219e-06,
      "loss": 0.0569,
      "step": 32000
    },
    {
      "epoch": 3.4460820697699077,
      "grad_norm": 18.918373107910156,
      "learning_rate": 6.222881984943273e-06,
      "loss": 0.063,
      "step": 32500
    },
    {
      "epoch": 3.4990987169971373,
      "grad_norm": 0.1592787504196167,
      "learning_rate": 6.010815396034355e-06,
      "loss": 0.0521,
      "step": 33000
    },
    {
      "epoch": 3.5521153642243664,
      "grad_norm": 1.2635927200317383,
      "learning_rate": 5.7987488071254386e-06,
      "loss": 0.0462,
      "step": 33500
    },
    {
      "epoch": 3.605132011451596,
      "grad_norm": 0.11182837933301926,
      "learning_rate": 5.58668221821652e-06,
      "loss": 0.0496,
      "step": 34000
    },
    {
      "epoch": 3.658148658678825,
      "grad_norm": 0.06605973839759827,
      "learning_rate": 5.375039762485421e-06,
      "loss": 0.0452,
      "step": 34500
    },
    {
      "epoch": 3.7111653059060545,
      "grad_norm": 0.06875377893447876,
      "learning_rate": 5.162973173576503e-06,
      "loss": 0.0539,
      "step": 35000
    },
    {
      "epoch": 3.764181953133284,
      "grad_norm": 0.022074395790696144,
      "learning_rate": 4.951330717845404e-06,
      "loss": 0.0531,
      "step": 35500
    },
    {
      "epoch": 3.817198600360513,
      "grad_norm": 0.02478439174592495,
      "learning_rate": 4.739264128936486e-06,
      "loss": 0.0524,
      "step": 36000
    },
    {
      "epoch": 3.8702152475877427,
      "grad_norm": 6.154102325439453,
      "learning_rate": 4.527197540027569e-06,
      "loss": 0.0472,
      "step": 36500
    },
    {
      "epoch": 3.923231894814972,
      "grad_norm": 0.02101670205593109,
      "learning_rate": 4.315130951118652e-06,
      "loss": 0.0518,
      "step": 37000
    },
    {
      "epoch": 3.9762485420422014,
      "grad_norm": 0.023533329367637634,
      "learning_rate": 4.1030643622097345e-06,
      "loss": 0.0503,
      "step": 37500
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.6106072068214417,
      "eval_runtime": 97.8356,
      "eval_samples_per_second": 511.031,
      "eval_steps_per_second": 31.941,
      "step": 37724
    },
    {
      "epoch": 4.029265189269431,
      "grad_norm": 0.02375461533665657,
      "learning_rate": 3.890997773300817e-06,
      "loss": 0.038,
      "step": 38000
    },
    {
      "epoch": 4.0822818364966595,
      "grad_norm": 0.03869308903813362,
      "learning_rate": 3.6789311843918994e-06,
      "loss": 0.037,
      "step": 38500
    },
    {
      "epoch": 4.135298483723889,
      "grad_norm": 0.02386109158396721,
      "learning_rate": 3.466864595482982e-06,
      "loss": 0.0365,
      "step": 39000
    },
    {
      "epoch": 4.188315130951119,
      "grad_norm": 0.06560428440570831,
      "learning_rate": 3.2547980065740646e-06,
      "loss": 0.035,
      "step": 39500
    },
    {
      "epoch": 4.241331778178348,
      "grad_norm": 0.05027368664741516,
      "learning_rate": 3.043155550842965e-06,
      "loss": 0.0382,
      "step": 40000
    },
    {
      "epoch": 4.294348425405578,
      "grad_norm": 0.02159079536795616,
      "learning_rate": 2.8310889619340478e-06,
      "loss": 0.0341,
      "step": 40500
    },
    {
      "epoch": 4.347365072632806,
      "grad_norm": 16.980615615844727,
      "learning_rate": 2.61902237302513e-06,
      "loss": 0.0414,
      "step": 41000
    },
    {
      "epoch": 4.400381719860036,
      "grad_norm": 0.018210677430033684,
      "learning_rate": 2.4069557841162126e-06,
      "loss": 0.0305,
      "step": 41500
    },
    {
      "epoch": 4.453398367087265,
      "grad_norm": 0.8860397338867188,
      "learning_rate": 2.1948891952072955e-06,
      "loss": 0.0353,
      "step": 42000
    },
    {
      "epoch": 4.506415014314495,
      "grad_norm": 0.028733311221003532,
      "learning_rate": 1.982822606298378e-06,
      "loss": 0.0313,
      "step": 42500
    },
    {
      "epoch": 4.5594316615417245,
      "grad_norm": 0.022845366969704628,
      "learning_rate": 1.7711801505672782e-06,
      "loss": 0.0345,
      "step": 43000
    },
    {
      "epoch": 4.612448308768953,
      "grad_norm": 0.01575952209532261,
      "learning_rate": 1.5591135616583608e-06,
      "loss": 0.0362,
      "step": 43500
    },
    {
      "epoch": 4.665464955996183,
      "grad_norm": 0.01698133908212185,
      "learning_rate": 1.3470469727494434e-06,
      "loss": 0.0366,
      "step": 44000
    },
    {
      "epoch": 4.718481603223412,
      "grad_norm": 0.09338176250457764,
      "learning_rate": 1.135404517018344e-06,
      "loss": 0.0334,
      "step": 44500
    },
    {
      "epoch": 4.771498250450642,
      "grad_norm": 0.015313046984374523,
      "learning_rate": 9.233379281094263e-07,
      "loss": 0.0384,
      "step": 45000
    },
    {
      "epoch": 4.8245148976778705,
      "grad_norm": 0.2981259226799011,
      "learning_rate": 7.11271339200509e-07,
      "loss": 0.0347,
      "step": 45500
    },
    {
      "epoch": 4.8775315449051,
      "grad_norm": 0.01825479045510292,
      "learning_rate": 4.992047502915916e-07,
      "loss": 0.0339,
      "step": 46000
    },
    {
      "epoch": 4.9305481921323295,
      "grad_norm": 0.7666695713996887,
      "learning_rate": 2.8713816138267415e-07,
      "loss": 0.033,
      "step": 46500
    },
    {
      "epoch": 4.983564839359559,
      "grad_norm": 0.015276407822966576,
      "learning_rate": 7.507157247375677e-08,
      "loss": 0.0325,
      "step": 47000
    }
  ],
  "logging_steps": 500,
  "max_steps": 47155,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.9627678373184e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
